*About Machine Learning Models*

XGBoost

How it Works:
1. Gradient Boosting : Train new trees to correct previously error results
2. Ensemble Lerning : Each new tree minimizes the residual errors of the ensemble formed by previous trees
3. Regularization : Prevents overfitting
4. Parallel Processing
5. Automatically handle missing values

Hyperparameter
Use cross-validation to find the best parameters to use with the model and dataset. Involves testing various combination of parameters.