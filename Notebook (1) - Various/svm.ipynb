{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SVM</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\arell\\Documents\\1_ALF\\data\\malicious_2021.csv', low_memory=False)\n",
    "\n",
    "# Select features and target columns\n",
    "features = ['Querylength', 'domain_token_count', 'path_token_count',\n",
    "            'avgdomaintokenlen', 'longdomaintokenlen', 'avgpathtokenlen', 'tld',\n",
    "            'charcompvowels', 'charcompace', 'ldl_url', 'ldl_domain', 'ldl_path',\n",
    "            'ldl_filename', 'ldl_getArg', 'dld_url', 'dld_domain', 'dld_path',\n",
    "            'dld_filename', 'dld_getArg', 'urlLen', 'domainlength', 'pathLength',\n",
    "            'subDirLen', 'fileNameLen', 'this.fileExtLen', 'ArgLen', 'pathurlRatio',\n",
    "            'ArgUrlRatio', 'argDomanRatio', 'domainUrlRatio', 'pathDomainRatio',\n",
    "            'argPathRatio', 'executable', 'isPortEighty', 'NumberofDotsinURL',\n",
    "            'ISIpAddressInDomainName', 'CharacterContinuityRate',\n",
    "            'LongestVariableValue', 'URL_DigitCount', 'host_DigitCount',\n",
    "            'Directory_DigitCount', 'File_name_DigitCount', 'Extension_DigitCount',\n",
    "            'Query_DigitCount', 'URL_Letter_Count', 'host_letter_count',\n",
    "            'Directory_LetterCount', 'Filename_LetterCount',\n",
    "            'Extension_LetterCount', 'Query_LetterCount', 'LongestPathTokenLength',\n",
    "            'Domain_LongestWordLength', 'Path_LongestWordLength',\n",
    "            'sub-Directory_LongestWordLength', 'Arguments_LongestWordLength',\n",
    "            'URL_sensitiveWord', 'URLQueries_variable', 'spcharUrl',\n",
    "            'delimeter_Domain', 'delimeter_path', 'delimeter_Count',\n",
    "            'NumberRate_URL', 'NumberRate_Domain', 'NumberRate_DirectoryName',\n",
    "            'NumberRate_FileName', 'NumberRate_Extension', 'NumberRate_AfterPath',\n",
    "            'SymbolCount_URL', 'SymbolCount_Domain', 'SymbolCount_Directoryname',\n",
    "            'SymbolCount_FileName', 'SymbolCount_Extension',\n",
    "            'SymbolCount_Afterpath', 'Entropy_URL', 'Entropy_Domain',\n",
    "            'Entropy_DirectoryName', 'Entropy_Filename', 'Entropy_Extension',\n",
    "            'Entropy_Afterpath', 'URL_Type_obf_Type']\n",
    "\n",
    "# Clean the dataset by removing NaNs and infinities in numeric columns only\n",
    "df_cleaned = df.copy()\n",
    "df_cleaned['tld'] = df_cleaned['tld'].astype(str)  # Convert 'tld' to string\n",
    "numeric_features = [f for f in features if f != 'tld']\n",
    "df_cleaned = df_cleaned[np.isfinite(df_cleaned[numeric_features]).all(axis=1)]\n",
    "\n",
    "# Label encoding for TLD (since it's categorical)\n",
    "df_cleaned['tld_encoded'] = LabelEncoder().fit_transform(df_cleaned['tld'])\n",
    "\n",
    "# Combine all features (without the original 'tld' column)\n",
    "X = df_cleaned[numeric_features + ['tld_encoded']]\n",
    "\n",
    "# Standardize features (important for SVM)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Binary classification: Benign vs Malicious\n",
    "df_cleaned['binary_label'] = df_cleaned['url_type'].apply(lambda x: 0 if x == 'benign' else 1)\n",
    "\n",
    "# Train-Test Split for Binary Classification (Benign vs Malicious)\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
    "    X_scaled, df_cleaned['binary_label'], test_size=0.3, random_state=42, stratify=df_cleaned['binary_label']\n",
    ")\n",
    "\n",
    "# Initialize the SVM classifier for binary classification\n",
    "svm_binary_classifier = SVC(random_state=42)\n",
    "\n",
    "# Fit the model on the training data for binary classification\n",
    "svm_binary_classifier.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "# Make predictions on the training and test data for binary classification\n",
    "y_train_pred_bin = svm_binary_classifier.predict(X_train_bin)\n",
    "y_test_pred_bin = svm_binary_classifier.predict(X_test_bin)\n",
    "\n",
    "# Evaluate the model on the training data for binary classification\n",
    "print(\"Binary Classification Report (Benign vs Malicious) - Training Data:\")\n",
    "print(classification_report(y_train_bin, y_train_pred_bin))\n",
    "print(\"Binary Classification Accuracy (Training):\", accuracy_score(y_train_bin, y_train_pred_bin))\n",
    "\n",
    "# Evaluate the model on the test data for binary classification\n",
    "print(\"\\nBinary Classification Report (Benign vs Malicious) - Test Data:\")\n",
    "print(classification_report(y_test_bin, y_test_pred_bin))\n",
    "print(\"Binary Classification Accuracy (Test):\", accuracy_score(y_test_bin, y_test_pred_bin))\n",
    "\n",
    "# Multiclass Classification for types of malicious URLs\n",
    "# Only consider the non-benign entries\n",
    "malicious_df = df_cleaned[df_cleaned['binary_label'] == 1].copy()\n",
    "\n",
    "# Encode URL types into categories: spam, phishing, malware, defacement\n",
    "label_encoder = LabelEncoder()\n",
    "malicious_df['url_type_encoded'] = label_encoder.fit_transform(malicious_df['url_type'])\n",
    "\n",
    "# Select features and target for multiclass classification\n",
    "X_multi = malicious_df[numeric_features + ['tld_encoded']]\n",
    "X_multi_scaled = scaler.transform(X_multi)  # Scale features for multiclass classification\n",
    "y_multi = malicious_df['url_type_encoded']\n",
    "\n",
    "# Train-Test Split for Multiclass Classification\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_multi_scaled, y_multi, test_size=0.3, random_state=42, stratify=y_multi\n",
    ")\n",
    "\n",
    "# Initialize the SVM classifier for multiclass classification\n",
    "svm_multiclass_classifier = SVC(random_state=42)\n",
    "\n",
    "# Fit the model on the training data for multiclass classification\n",
    "svm_multiclass_classifier.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Make predictions on the training and test data for multiclass classification\n",
    "y_train_pred_multi = svm_multiclass_classifier.predict(X_train_multi)\n",
    "y_test_pred_multi = svm_multiclass_classifier.predict(X_test_multi)\n",
    "\n",
    "# Evaluate the model on the training data for multiclass classification\n",
    "print(\"\\nMulticlass Classification Report (Malicious Type) - Training Data:\")\n",
    "print(classification_report(y_train_multi, y_train_pred_multi))\n",
    "print(\"Multiclass Classification Accuracy (Training):\", accuracy_score(y_train_multi, y_train_pred_multi))\n",
    "\n",
    "# Evaluate the model on the test data for multiclass classification\n",
    "print(\"\\nMulticlass Classification Report (Malicious Type) - Test Data:\")\n",
    "print(classification_report(y_test_multi, y_test_pred_multi))\n",
    "print(\"Multiclass Classification Accuracy (Test):\", accuracy_score(y_test_multi, y_test_pred_multi))\n",
    "\n",
    "# Summary of overall results\n",
    "print(\"\\nOverall Results Summary:\")\n",
    "print(f\"Binary Classification - Training Accuracy: {accuracy_score(y_train_bin, y_train_pred_bin):.4f}\")\n",
    "print(f\"Binary Classification - Test Accuracy: {accuracy_score(y_test_bin, y_test_pred_bin):.4f}\")\n",
    "print(f\"Multiclass Classification - Training Accuracy: {accuracy_score(y_train_multi, y_train_pred_multi):.4f}\")\n",
    "print(f\"Multiclass Classification - Test Accuracy: {accuracy_score(y_test_multi, y_test_pred_multi):.4f}\")\n",
    "\n",
    "# Show encoded url_type\n",
    "print(\"\\nEncoded URL Types:\")\n",
    "print(malicious_df[['url_type', 'url_type_encoded']].drop_duplicates().reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SVM + SMOTE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\arell\\Documents\\1_ALF\\data\\malicious_2021.csv', low_memory=False)\n",
    "\n",
    "# Select features and target columns\n",
    "features = ['Querylength', 'domain_token_count', 'path_token_count',\n",
    "            'avgdomaintokenlen', 'longdomaintokenlen', 'avgpathtokenlen', 'tld',\n",
    "            'charcompvowels', 'charcompace', 'ldl_url', 'ldl_domain', 'ldl_path',\n",
    "            'ldl_filename', 'ldl_getArg', 'dld_url', 'dld_domain', 'dld_path',\n",
    "            'dld_filename', 'dld_getArg', 'urlLen', 'domainlength', 'pathLength',\n",
    "            'subDirLen', 'fileNameLen', 'this.fileExtLen', 'ArgLen', 'pathurlRatio',\n",
    "            'ArgUrlRatio', 'argDomanRatio', 'domainUrlRatio', 'pathDomainRatio',\n",
    "            'argPathRatio', 'executable', 'isPortEighty', 'NumberofDotsinURL',\n",
    "            'ISIpAddressInDomainName', 'CharacterContinuityRate',\n",
    "            'LongestVariableValue', 'URL_DigitCount', 'host_DigitCount',\n",
    "            'Directory_DigitCount', 'File_name_DigitCount', 'Extension_DigitCount',\n",
    "            'Query_DigitCount', 'URL_Letter_Count', 'host_letter_count',\n",
    "            'Directory_LetterCount', 'Filename_LetterCount',\n",
    "            'Extension_LetterCount', 'Query_LetterCount', 'LongestPathTokenLength',\n",
    "            'Domain_LongestWordLength', 'Path_LongestWordLength',\n",
    "            'sub-Directory_LongestWordLength', 'Arguments_LongestWordLength',\n",
    "            'URL_sensitiveWord', 'URLQueries_variable', 'spcharUrl',\n",
    "            'delimeter_Domain', 'delimeter_path', 'delimeter_Count',\n",
    "            'NumberRate_URL', 'NumberRate_Domain', 'NumberRate_DirectoryName',\n",
    "            'NumberRate_FileName', 'NumberRate_Extension', 'NumberRate_AfterPath',\n",
    "            'SymbolCount_URL', 'SymbolCount_Domain', 'SymbolCount_Directoryname',\n",
    "            'SymbolCount_FileName', 'SymbolCount_Extension',\n",
    "            'SymbolCount_Afterpath', 'Entropy_URL', 'Entropy_Domain',\n",
    "            'Entropy_DirectoryName', 'Entropy_Filename', 'Entropy_Extension',\n",
    "            'Entropy_Afterpath', 'URL_Type_obf_Type']\n",
    "\n",
    "# Clean the dataset by removing NaNs and infinities in numeric columns only\n",
    "df_cleaned = df.copy()\n",
    "df_cleaned['tld'] = df_cleaned['tld'].astype(str)  # Convert 'tld' to string\n",
    "numeric_features = [f for f in features if f != 'tld']\n",
    "df_cleaned = df_cleaned[np.isfinite(df_cleaned[numeric_features]).all(axis=1)]\n",
    "\n",
    "# Label encoding for TLD (since it's categorical)\n",
    "df_cleaned['tld_encoded'] = LabelEncoder().fit_transform(df_cleaned['tld'])\n",
    "\n",
    "# Combine all features (without the original 'tld' column)\n",
    "X = df_cleaned[numeric_features + ['tld_encoded']]\n",
    "\n",
    "# Standardize features (important for SVM)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Binary classification: Benign vs Malicious\n",
    "df_cleaned['binary_label'] = df_cleaned['url_type'].apply(lambda x: 0 if x == 'benign' else 1)\n",
    "\n",
    "# Train-Test Split for Binary Classification (Benign vs Malicious)\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
    "    X_scaled, df_cleaned['binary_label'], test_size=0.3, random_state=42, stratify=df_cleaned['binary_label']\n",
    ")\n",
    "\n",
    "# Apply SMOTE for the training set to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bin_smote, y_train_bin_smote = smote.fit_resample(X_train_bin, y_train_bin)\n",
    "\n",
    "# Initialize the SVM classifier for binary classification\n",
    "svm_binary_classifier = SVC(random_state=42)\n",
    "\n",
    "# Fit the model on the SMOTE-augmented training data for binary classification\n",
    "svm_binary_classifier.fit(X_train_bin_smote, y_train_bin_smote)\n",
    "\n",
    "# Make predictions on the training and test data for binary classification\n",
    "y_train_pred_bin = svm_binary_classifier.predict(X_train_bin_smote)\n",
    "y_test_pred_bin = svm_binary_classifier.predict(X_test_bin)\n",
    "\n",
    "# Evaluate the model on the training data for binary classification\n",
    "print(\"Binary Classification Report (Benign vs Malicious) - Training Data:\")\n",
    "print(classification_report(y_train_bin_smote, y_train_pred_bin))\n",
    "print(\"Binary Classification Accuracy (Training):\", accuracy_score(y_train_bin_smote, y_train_pred_bin))\n",
    "\n",
    "# Evaluate the model on the test data for binary classification\n",
    "print(\"\\nBinary Classification Report (Benign vs Malicious) - Test Data:\")\n",
    "print(classification_report(y_test_bin, y_test_pred_bin))\n",
    "print(\"Binary Classification Accuracy (Test):\", accuracy_score(y_test_bin, y_test_pred_bin))\n",
    "\n",
    "# Multiclass Classification for types of malicious URLs\n",
    "# Only consider the non-benign entries\n",
    "malicious_df = df_cleaned[df_cleaned['binary_label'] == 1].copy()\n",
    "\n",
    "# Encode URL types into categories: spam, phishing, malware, defacement\n",
    "label_encoder = LabelEncoder()\n",
    "malicious_df['url_type_encoded'] = label_encoder.fit_transform(malicious_df['url_type'])\n",
    "\n",
    "# Select features and target for multiclass classification\n",
    "X_multi = malicious_df[numeric_features + ['tld_encoded']]\n",
    "X_multi_scaled = scaler.transform(X_multi)  # Scale features for multiclass classification\n",
    "y_multi = malicious_df['url_type_encoded']\n",
    "\n",
    "# Train-Test Split for Multiclass Classification\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_multi_scaled, y_multi, test_size=0.3, random_state=42, stratify=y_multi\n",
    ")\n",
    "\n",
    "# Apply SMOTE for the training set in multiclass classification\n",
    "X_train_multi_smote, y_train_multi_smote = smote.fit_resample(X_train_multi, y_train_multi)\n",
    "\n",
    "# Initialize the SVM classifier for multiclass classification\n",
    "svm_multiclass_classifier = SVC(random_state=42)\n",
    "\n",
    "# Fit the model on the SMOTE-augmented training data for multiclass classification\n",
    "svm_multiclass_classifier.fit(X_train_multi_smote, y_train_multi_smote)\n",
    "\n",
    "# Make predictions on the training and test data for multiclass classification\n",
    "y_train_pred_multi = svm_multiclass_classifier.predict(X_train_multi_smote)\n",
    "y_test_pred_multi = svm_multiclass_classifier.predict(X_test_multi)\n",
    "\n",
    "# Evaluate the model on the training data for multiclass classification\n",
    "print(\"\\nMulticlass Classification Report (Malicious Type) - Training Data:\")\n",
    "print(classification_report(y_train_multi_smote, y_train_pred_multi))\n",
    "print(\"Multiclass Classification Accuracy (Training):\", accuracy_score(y_train_multi_smote, y_train_pred_multi))\n",
    "\n",
    "# Evaluate the model on the test data for multiclass classification\n",
    "print(\"\\nMulticlass Classification Report (Malicious Type) - Test Data:\")\n",
    "print(classification_report(y_test_multi, y_test_pred_multi))\n",
    "print(\"Multiclass Classification Accuracy (Test):\", accuracy_score(y_test_multi, y_test_pred_multi))\n",
    "\n",
    "# Summary of overall results\n",
    "print(\"\\nOverall Results Summary:\")\n",
    "print(f\"Binary Classification - Training Accuracy: {accuracy_score(y_train_bin_smote, y_train_pred_bin):.4f}\")\n",
    "print(f\"Binary Classification - Test Accuracy: {accuracy_score(y_test_bin, y_test_pred_bin):.4f}\")\n",
    "print(f\"Multiclass Classification - Training Accuracy: {accuracy_score(y_train_multi_smote, y_train_pred_multi):.4f}\")\n",
    "print(f\"Multiclass Classification - Test Accuracy: {accuracy_score(y_test_multi, y_test_pred_multi):.4f}\")\n",
    "\n",
    "# Show encoded url_type\n",
    "print(\"\\nEncoded URL Types:\")\n",
    "print(malicious_df[['url_type', 'url_type_encoded']].drop_duplicates().reset_index(drop=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
